{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3177787",
   "metadata": {},
   "source": [
    "Implement a CNN on Tomato dataset using batch sizes of 32 and 64 separately. Keep the learning \n",
    "rate fixed at 0.0001 and compare results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fabd71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6\n",
      "\n",
      "Training with batch size: 32\n",
      "Found 11108 images belonging to 6 classes.\n",
      "Found 2495 images belonging to 6 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 200ms/step - accuracy: 0.3344 - loss: 1.5898 - val_accuracy: 0.6289 - val_loss: 0.9397\n",
      "Epoch 2/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 207ms/step - accuracy: 0.6631 - loss: 0.9391 - val_accuracy: 0.6882 - val_loss: 0.8038\n",
      "Epoch 3/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 222ms/step - accuracy: 0.7343 - loss: 0.7498 - val_accuracy: 0.6986 - val_loss: 0.7754\n",
      "Epoch 4/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 207ms/step - accuracy: 0.7676 - loss: 0.6504 - val_accuracy: 0.7535 - val_loss: 0.7169\n",
      "Epoch 5/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 214ms/step - accuracy: 0.7901 - loss: 0.6019 - val_accuracy: 0.7483 - val_loss: 0.7239\n",
      "Epoch 6/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 191ms/step - accuracy: 0.8071 - loss: 0.5307 - val_accuracy: 0.7218 - val_loss: 0.8559\n",
      "Epoch 7/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 149ms/step - accuracy: 0.8219 - loss: 0.5110 - val_accuracy: 0.6810 - val_loss: 0.9185\n",
      "Epoch 8/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 142ms/step - accuracy: 0.8324 - loss: 0.4805 - val_accuracy: 0.7780 - val_loss: 0.6164\n",
      "Epoch 9/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 135ms/step - accuracy: 0.8364 - loss: 0.4646 - val_accuracy: 0.7932 - val_loss: 0.6058\n",
      "Epoch 10/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 120ms/step - accuracy: 0.8473 - loss: 0.4240 - val_accuracy: 0.7784 - val_loss: 0.6726\n",
      "Epoch 11/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 122ms/step - accuracy: 0.8470 - loss: 0.4239 - val_accuracy: 0.7856 - val_loss: 0.6245\n",
      "Epoch 12/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 128ms/step - accuracy: 0.8610 - loss: 0.3941 - val_accuracy: 0.8236 - val_loss: 0.5765\n",
      "Epoch 13/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 130ms/step - accuracy: 0.8598 - loss: 0.3882 - val_accuracy: 0.8164 - val_loss: 0.5823\n",
      "Epoch 14/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 129ms/step - accuracy: 0.8744 - loss: 0.3597 - val_accuracy: 0.7904 - val_loss: 0.6297\n",
      "Epoch 15/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 140ms/step - accuracy: 0.8799 - loss: 0.3445 - val_accuracy: 0.7752 - val_loss: 0.8652\n",
      "Epoch 16/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 137ms/step - accuracy: 0.8750 - loss: 0.3438 - val_accuracy: 0.8397 - val_loss: 0.5264\n",
      "Epoch 17/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 147ms/step - accuracy: 0.8893 - loss: 0.3251 - val_accuracy: 0.7359 - val_loss: 0.9874\n",
      "Epoch 18/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 122ms/step - accuracy: 0.8842 - loss: 0.3254 - val_accuracy: 0.7719 - val_loss: 1.0050\n",
      "Epoch 19/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 117ms/step - accuracy: 0.8826 - loss: 0.3282 - val_accuracy: 0.8325 - val_loss: 0.5030\n",
      "Epoch 20/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 119ms/step - accuracy: 0.8912 - loss: 0.3157 - val_accuracy: 0.7956 - val_loss: 0.6678\n",
      "\n",
      "Training with batch size: 64\n",
      "Found 11108 images belonging to 6 classes.\n",
      "Found 2495 images belonging to 6 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 20:53:37.429847: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[64,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,3,128,128]{3,2,1,0} %bitcast.4699, f32[32,3,3,3]{3,2,1,0} %bitcast.4706, f32[32]{0} %bitcast.5244), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_6_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:53:37.530459: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[64,64,61,61]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,32,63,63]{3,2,1,0} %bitcast.5308, f32[64,32,3,3]{3,2,1,0} %bitcast.4727, f32[64]{0} %bitcast.5368), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_7_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:53:37.867897: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[64,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,30,30]{3,2,1,0} %bitcast.5432, f32[128,64,3,3]{3,2,1,0} %bitcast.4746, f32[128]{0} %bitcast.5492), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_8_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 29/174\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 224ms/step - accuracy: 0.1698 - loss: 1.7956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 20:53:48.732776: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[36,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[36,3,128,128]{3,2,1,0} %bitcast.4699, f32[32,3,3,3]{3,2,1,0} %bitcast.4706, f32[32]{0} %bitcast.5244), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_6_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:53:48.816814: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[36,64,61,61]{3,2,1,0}, u8[0]{0}) custom-call(f32[36,32,63,63]{3,2,1,0} %bitcast.5308, f32[64,32,3,3]{3,2,1,0} %bitcast.4727, f32[64]{0} %bitcast.5368), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_7_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:53:49.048013: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[36,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[36,64,30,30]{3,2,1,0} %bitcast.5432, f32[128,64,3,3]{3,2,1,0} %bitcast.4746, f32[128]{0} %bitcast.5492), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_8_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.2512 - loss: 1.7078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 20:54:24.626880: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[64,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,3,128,128]{3,2,1,0} %bitcast.531, f32[32,3,3,3]{3,2,1,0} %bitcast.538, f32[32]{0} %bitcast.540), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_6_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:54:24.704037: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[64,64,61,61]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,32,63,63]{3,2,1,0} %bitcast.548, f32[64,32,3,3]{3,2,1,0} %bitcast.555, f32[64]{0} %bitcast.557), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_7_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:54:24.170543: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[64,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,30,30]{3,2,1,0} %bitcast.563, f32[128,64,3,3]{3,2,1,0} %bitcast.570, f32[128]{0} %bitcast.572), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_8_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:54:27.003830: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[63,32,126,126]{3,2,1,0}, u8[0]{0}) custom-call(f32[63,3,128,128]{3,2,1,0} %bitcast.531, f32[32,3,3,3]{3,2,1,0} %bitcast.538, f32[32]{0} %bitcast.540), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_6_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:54:27.100544: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[63,64,61,61]{3,2,1,0}, u8[0]{0}) custom-call(f32[63,32,63,63]{3,2,1,0} %bitcast.548, f32[64,32,3,3]{3,2,1,0} %bitcast.555, f32[64]{0} %bitcast.557), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_7_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-05-22 20:54:27.378600: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[63,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[63,64,30,30]{3,2,1,0} %bitcast.563, f32[128,64,3,3]{3,2,1,0} %bitcast.570, f32[128]{0} %bitcast.572), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_8_1/convolution\" source_file=\"/home/adithya/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 270ms/step - accuracy: 0.2517 - loss: 1.7070 - val_accuracy: 0.4689 - val_loss: 1.2538\n",
      "Epoch 2/20\n",
      "\u001b[1m 95/174\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 252ms/step - accuracy: 0.5335 - loss: 1.2650"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     87\u001b[39m     model = build_cnn_model((IMG_HEIGHT, IMG_WIDTH, \u001b[32m3\u001b[39m), num_classes)\n\u001b[32m     88\u001b[39m     model.compile(\n\u001b[32m     89\u001b[39m         optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n\u001b[32m     90\u001b[39m         loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     91\u001b[39m         metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     92\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     histories.append(history)\n\u001b[32m    102\u001b[39m plot_history(histories, BATCH_SIZES)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m ):\n\u001b[32m    219\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[39m, in \u001b[36m_OptionalImpl.has_value\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Deep_Learning/tensorflow_env/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[39m, in \u001b[36moptional_has_value\u001b[39m\u001b[34m(optional, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    171\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionalHasValue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZES = [32, 64]\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "train_dir = '/home/adithya/Deep_Learning/DL3_Dataset/Tomato/Train'\n",
    "val_dir = '/home/adithya/Deep_Learning/DL3_Dataset/Tomato/Val'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def plot_history(histories, batch_sizes):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for i, history in enumerate(histories):\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['val_accuracy'], label=f'Batch {batch_sizes[i]}')\n",
    "        plt.title('Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['val_loss'], label=f'Batch {batch_sizes[i]}')\n",
    "        plt.title('Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(train_dir):\n",
    "        raise FileNotFoundError(f\"Training directory '{train_dir}' does not exist. Please check your dataset path.\")\n",
    "\n",
    "    class_folders = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
    "    if not class_folders:\n",
    "        raise ValueError(f\"No class subfolders found in '{train_dir}'. Please organize your dataset as '{train_dir}/class_name/'.\")\n",
    "    num_classes = len(class_folders)\n",
    "    print(f'Number of classes: {num_classes}')\n",
    "\n",
    "    histories = []\n",
    "\n",
    "    for batch_size in BATCH_SIZES:\n",
    "        print(f\"\\nTraining with batch size: {batch_size}\")\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        val_generator = val_datagen.flow_from_directory(\n",
    "            val_dir,\n",
    "            target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "\n",
    "        model = build_cnn_model((IMG_HEIGHT, IMG_WIDTH, 3), num_classes)\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=val_generator,\n",
    "            verbose=1\n",
    "        )\n",
    "        histories.append(history)\n",
    "\n",
    "    plot_history(histories, BATCH_SIZES)\n",
    "\n",
    "    for i, batch_size in enumerate(BATCH_SIZES):\n",
    "        val_acc = histories[i].history['val_accuracy'][-1]\n",
    "        print(f\"Batch Size {batch_size}: Final Validation Accuracy = {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
